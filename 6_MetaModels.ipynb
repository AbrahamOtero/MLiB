{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhVhTHTeonwWjNRVVQUhvw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbrahamOtero/MLiB/blob/main/6_MetaModels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combination of models\n",
        "We import the libraries that we are going to need:"
      ],
      "metadata": {
        "id": "X7T4z_H9CERP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Hvg5dtqxsw0d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Voting\n",
        "\n",
        "We will start by implementing a voting strategy using **VotingClassifier**. We will use three models (although you can add more models if you want): a decision tree, K nearest neighbors, and a support vector machine. We will apply it to the diabetes dataset, and perform a 10-fold evaluation."
      ],
      "metadata": {
        "id": "DLLLQbL2t9LU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/AbrahamOtero/MLiB/main/datasets/diabetes.csv'\n",
        "\n",
        "diabetes = pd.read_csv(url)\n",
        "\n",
        "# The featrures\n",
        "X = diabetes.iloc[:, :-1]\n",
        "# The class\n",
        "y = diabetes.iloc[:,-1]\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# We will reserve a set of test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "\n",
        "# We build the voting-based classifier\n",
        "voting_clf = VotingClassifier(\n",
        "    # Map of classifiers that \"vote\". We indicate their name (any string of characters) and the classifier\n",
        "    estimators=[\n",
        "        ('dt', DecisionTreeClassifier()),\n",
        "        ('knn', KNeighborsClassifier()),\n",
        "        ('gnb', GaussianNB())\n",
        "    ]\n",
        ")\n",
        "voting_clf.fit(X_train, y_train)\n",
        "\n",
        "scores = cross_val_score(voting_clf, X_train, y_train, cv=10, scoring=\"accuracy\")\n",
        "# Calculate and display the average accuracy value and standard deviation for the scores of each fold\n",
        "print(\"Mean accuracy:\", scores.mean())\n",
        "print(\"Standard deviation:\", scores.std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxtGJ4-ctAG1",
        "outputId": "64eac2dd-d113-4d01-f972-785e3f39ee24"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean accuracy: 0.7586956521739131\n",
            "Standard deviation: 0.05185591496468073\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how each of the three classifiers performs, as well as the performance of the voting model composed of the three classifiers. We will use the 10% of data that we saved for testing:"
      ],
      "metadata": {
        "id": "0e702xQuFFdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for name, clf in voting_clf.named_estimators_.items():\n",
        "    print(name, \"=\", clf.score(X_test, y_test))\n",
        "\n",
        "print(\"Voting: \", voting_clf.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvA2Rah4t0GW",
        "outputId": "80f1fff8-8911-4ee0-ace9-ba9f428f6bf5"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dt = 0.7207792207792207\n",
            "knn = 0.7142857142857143\n",
            "gnb = 0.7597402597402597\n",
            "Voting:  0.7792207792207793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that the performance of the model composed of the three classifiers is slightly higher than the performance of each of them. In practice this does not always have to be the case (especially if the errors of the different classifiers are correlated, or if one classifier is much better than the others). But we can often improve the performance of each individual model by this aggregation.\n",
        "\n"
      ],
      "metadata": {
        "id": "dAPz1YBdFHY9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bagging\n",
        "\n",
        "An obvious approach to voting is to use multiple versions of the same classifier over altered versions (using sampling) of the data set. For example, using multiple decision trees. We can do this easily by using **BaggingClassifier**:"
      ],
      "metadata": {
        "id": "cil0QXvTt_sk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# To build each model we will use a number of samples equal to half of those available.\n",
        "n_smples = round(X_train.shape[1]/2)\n",
        "\n",
        "#We created a Bagging classifier composed of 100 decision trees\n",
        "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=100, max_samples=n_smples)\n",
        "socres = cross_val_score(bag_clf, X_train, y_train, cv=10, scoring=\"accuracy\")\n",
        "\n",
        "# Calculate and display the average accuracy value and standard deviation for the scores of each fold\n",
        "print(\"Mean accuracy:\", scores.mean())\n",
        "print(\"Standard deviation:\", scores.std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHOLwXdRuDT0",
        "outputId": "befa8d2a-f342-4e5a-d33c-e828b490eb87"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean accuracy: 0.7586956521739131\n",
            "Standard deviation: 0.05185591496468073\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forests\n",
        "\n",
        "A Random Forest is similar to a bag of decision trees. The main difference is that the decision trees are going to be built with different parameters (for example, maximum number of depth levels, a minimum number of instances in each different leaf). When using Bagging all the classifiers have been built with the same parameters, but with different dataset created using sampling.\n"
      ],
      "metadata": {
        "id": "vYKnhsD_uRY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rnd_clf = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "scores = cross_val_score(rnd_clf, X_train, y_train, cv=10, scoring=\"accuracy\")\n",
        "\n",
        "# Calculate and display the average accuracy value and standard deviation for the scores of each fold\n",
        "print(\"Mean accuracy:\", scores.mean())\n",
        "print(\"Standard deviation:\", scores.std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3C92yBOuS5T",
        "outputId": "63326b0d-c37a-4734-e708-aede0ba056ff"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean accuracy: 0.7543478260869565\n",
            "Standard deviation: 0.06152596390471699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "An interesting property of the Scikit Learn random tree classifier is that it can evaluate how important each attribute is based on how many times it was chosen to be used by the decision trees. To do this we will have to re-fit the classifier on the data (as we used cross_val_score in the previous code):"
      ],
      "metadata": {
        "id": "HKgCQGpZvCF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the classifier\n",
        "\n",
        "rnd_clf.fit(X_train, y_train)\n",
        "\n",
        "# Feature relevance\n",
        "for score, name in zip(rnd_clf.feature_importances_, diabetes.columns):\n",
        "    print(round(score, 2), name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wq-qIXS5ukvI",
        "outputId": "7fa7f8fb-ee3b-4d3c-d2ff-e617c2552366"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1 Pregnancies\n",
            "0.23 Glucose\n",
            "0.08 BloodPressure\n",
            "0.07 SkinThickness\n",
            "0.12 Insulin\n",
            "0.16 BMI\n",
            "0.12 DiabetesPedigreeFunction\n",
            "0.13 Age\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Boosting\n",
        "\n",
        "To use Boosting we can use **AdaBoostClassifier**:"
      ],
      "metadata": {
        "id": "e5XjWS2avQQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2), n_estimators=100, algorithm= 'SAMME')\n",
        "\n",
        "scores = cross_val_score(ada_clf, X_train, y_train, cv=10, scoring=\"accuracy\")\n",
        "\n",
        "# Calculate and display the average accuracy value and standard deviation for the scores of each fold\n",
        "print(\"Mean accuracy:\", scores.mean())\n",
        "print(\"Standard deviation:\", scores.std())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GbKADBIvH6U",
        "outputId": "835c2cb6-d595-4604-de6b-9a19c14f21c5"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean accuracy: 0.675\n",
            "Standard deviation: 0.13334396216138905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stacking\n",
        "\n",
        "Finall we will use Stacking using the classifier **StackingClassifier**:"
      ],
      "metadata": {
        "id": "Xbfoxezov5Sk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "\n",
        "stacking_clf = StackingClassifier(\n",
        "     # Map of level 0 models\n",
        "    estimators=[\n",
        "        ('dt', DecisionTreeClassifier()),\n",
        "        ('knn', KNeighborsClassifier()),\n",
        "        ('gnb', GaussianNB())\n",
        "    ],\n",
        "     # Level 1 model\n",
        "    final_estimator=DecisionTreeClassifier()\n",
        ")\n",
        "\n",
        "\n",
        "scores = cross_val_score(stacking_clf, X_train, y_train, cv=10, scoring=\"accuracy\")\n",
        "\n",
        "# Calculate and display the average accuracy value and standard deviation for the scores of each fold\n",
        "print(\"Mean accuracy:\", scores.mean())\n",
        "print(\"Standard deviation:\", scores.std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKQirudpv680",
        "outputId": "85a72ce5-b778-4c5d-a490-3c5ddf47fb65"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean accuracy: 0.658695652173913\n",
            "Standard deviation: 0.06877953051981033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation of classifiers based on cost\n",
        "\n",
        "Unfortunately Scikit learn does not have functionality directly to evaluate classifiers based on cost. We will rely on the following code (obtained from the following repository https://github.com/Treers/MetaCost). You will need to run this to create the cost based classifier. If you use it in your project, you will also need to load this class in the environment."
      ],
      "metadata": {
        "id": "nuiR6dIQZuGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Just run this code\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.base import clone\n",
        "\n",
        "class MetaCost(object):\n",
        "\n",
        "    \"\"\"A procedure for making error-based classifiers cost-sensitive\n",
        "\n",
        "    >>> from sklearn.datasets import load_iris\n",
        "    >>> from sklearn.linear_model import LogisticRegression\n",
        "    >>> import pandas as pd\n",
        "    >>> import numpy as np\n",
        "    >>> S = pd.DataFrame(load_iris().data)\n",
        "    >>> S['target'] = load_iris().target\n",
        "    >>> LR = LogisticRegression(solver='lbfgs', multi_class='multinomial')\n",
        "    >>> C = np.array([[0, 1, 1], [1, 0, 1], [1, 1, 0]])\n",
        "    >>> model = MetaCost(S, LR, C).fit('target', 3)\n",
        "    >>> model.predict_proba(load_iris().data[[2]])\n",
        "    >>> model.score(S[[0, 1, 2, 3]].values, S['target'])\n",
        "\n",
        "    .. note:: The form of the cost matrix C must be as follows:\n",
        "    +---------------+----------+----------+----------+\n",
        "    |  actual class |          |          |          |\n",
        "    +               |          |          |          |\n",
        "    |   +           | y(x)=j_1 | y(x)=j_2 | y(x)=j_3 |\n",
        "    |       +       |          |          |          |\n",
        "    |           +   |          |          |          |\n",
        "    |predicted class|          |          |          |\n",
        "    +---------------+----------+----------+----------+\n",
        "    |   h(x)=j_1    |    0     |    a     |     b    |\n",
        "    |   h(x)=j_2    |    c     |    0     |     d    |\n",
        "    |   h(x)=j_3    |    e     |    f     |     0    |\n",
        "    +---------------+----------+----------+----------+\n",
        "    | C = np.array([[0, a, b],[c, 0 , d],[e, f, 0]]) |\n",
        "    +------------------------------------------------+\n",
        "    \"\"\"\n",
        "    def __init__(self, S, L, C, m=50, n=1, p=True, q=True):\n",
        "        \"\"\"\n",
        "        :param S: The training set\n",
        "        :param L: A classification learning algorithm\n",
        "        :param C: A cost matrix\n",
        "        :param q: Is True iff all resamples are to be used  for each examples\n",
        "        :param m: The number of resamples to generate\n",
        "        :param n: The number of examples in each resample\n",
        "        :param p: Is True iff L produces class probabilities\n",
        "        \"\"\"\n",
        "        if not isinstance(S, pd.DataFrame):\n",
        "            raise ValueError('S must be a DataFrame object')\n",
        "        new_index = list(range(len(S)))\n",
        "        S.index = new_index\n",
        "        self.S = S\n",
        "        self.L = L\n",
        "        self.C = C\n",
        "        self.m = m\n",
        "        self.n = len(S) * n\n",
        "        self.p = p\n",
        "        self.q = q\n",
        "\n",
        "    def fit(self, flag, num_class):\n",
        "        \"\"\"\n",
        "        :param flag: The name of classification labels\n",
        "        :param num_class: The number of classes\n",
        "        :return: Classifier\n",
        "        \"\"\"\n",
        "        col = [col for col in self.S.columns if col != flag]\n",
        "        S_ = {}\n",
        "        M = []\n",
        "\n",
        "        for i in range(self.m):\n",
        "            # Let S_[i] be a resample of S with self.n examples\n",
        "            S_[i] = self.S.sample(n=self.n, replace=True)\n",
        "\n",
        "            X = S_[i][col].values\n",
        "            y = S_[i][flag].values\n",
        "\n",
        "            # Let M[i] = model produced by applying L to S_[i]\n",
        "            model = clone(self.L)\n",
        "            M.append(model.fit(X, y))\n",
        "\n",
        "        label = []\n",
        "        S_array = self.S[col].values\n",
        "        for i in range(len(self.S)):\n",
        "            if not self.q:\n",
        "                k_th = [k for k, v in S_.items() if i not in v.index]\n",
        "                M_ = list(np.array(M)[k_th])\n",
        "            else:\n",
        "                M_ = M\n",
        "\n",
        "            if self.p:\n",
        "                P_j = [model.predict_proba(S_array[[i]]) for model in M_]\n",
        "            else:\n",
        "                P_j = []\n",
        "                vector = [0] * num_class\n",
        "                for model in M_:\n",
        "                    vector[model.predict(S_array[[i]])] = 1\n",
        "                    P_j.append(vector)\n",
        "\n",
        "            # Calculate P(j|x)\n",
        "            P = np.array(np.mean(P_j, 0)).T\n",
        "\n",
        "            # Relabel\n",
        "            label.append(np.argmin(self.C.dot(P)))\n",
        "\n",
        "        # Model produced by applying L to S with relabeled y\n",
        "        X_train = self.S[col].values\n",
        "        y_train = np.array(label)\n",
        "        model_new = clone(self.L)\n",
        "        model_new.fit(X_train, y_train)\n",
        "\n",
        "        return model_new"
      ],
      "metadata": {
        "id": "8rNWkbHeSCaJ"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will start by training a decision tree without considering the cost. We will show the accuracy and the confusion matrix:"
      ],
      "metadata": {
        "id": "cc6381C7kZ-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Assuming X and y are already defined (from your previous code)\n",
        "# Create a Decision Tree classifier\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the classifier\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = dt_classifier.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "confusion_mat_tree = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_mat_tree)"
      ],
      "metadata": {
        "id": "lJFybkI_kZPu",
        "outputId": "63895119-94ad-4c65-8ac4-2b5d437a20cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7305194805194806\n",
            "Confusion Matrix:\n",
            "[[152  54]\n",
            " [ 29  73]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we train MetaCost, but with a cost matrix where all errors have the same cost."
      ],
      "metadata": {
        "id": "rSsp_xq3lvFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the cost matrix\n",
        "cost_matrix = np.array([[0, 1], [1, 0]])\n",
        "\n",
        "# Combine X_train and y_train into a single DataFrame\n",
        "# MetaCost needs the data in a DataFrame\n",
        "train_df = pd.DataFrame(data=X_train)\n",
        "train_df['Outcome'] = pd.array(y_train)\n",
        "\n",
        "# Create a MetaCost object with a DecisionTreeClassifier\n",
        "metacost_model = MetaCost(train_df, DecisionTreeClassifier(random_state=42), cost_matrix)\n",
        "\n",
        "# Fit the model to the training data.\n",
        "# We need to indicate the colum of the class ('Outcome') and the number of classes (2)\n",
        "model = metacost_model.fit('Outcome', 2)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "confusion_mat = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_mat)\n"
      ],
      "metadata": {
        "id": "yUUCouNikq4e",
        "outputId": "0be9a308-4a35-4d33-c737-8bb9ff706cc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7012987012987013\n",
            "Confusion Matrix:\n",
            "[[145  61]\n",
            " [ 31  71]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will carry out the training considering that classifying a diabetic patient as healthy has a cost 5 times higher than classifying a healthy patient as diabetic."
      ],
      "metadata": {
        "id": "xSALARA-mB5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the cost matrix\n",
        "cost_matrix = np.array([[0, 1], [5, 0]])\n",
        "\n",
        "# Combine X_train and y_train into a single DataFrame\n",
        "# MetaCost needs the data in a DataFrame\n",
        "train_df = pd.DataFrame(data=X_train)\n",
        "train_df['Outcome'] = pd.array(y_train)\n",
        "\n",
        "# Create a MetaCost object with a DecisionTreeClassifier\n",
        "metacost_model = MetaCost(train_df, DecisionTreeClassifier(random_state=42), cost_matrix)\n",
        "\n",
        "# Fit the model to the training data.\n",
        "# We need to indicate the colum of the class ('Outcome') and the number of classes (2)\n",
        "model = metacost_model.fit('Outcome', 2)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "confusion_mat = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_mat)\n",
        "\n",
        "\n",
        "# Calculate the cost of the classifier\n",
        "cost = np.sum(confusion_mat * cost_matrix)\n",
        "\n",
        "# Print the cost\n",
        "print(\"Cost:\", cost)"
      ],
      "metadata": {
        "id": "Y4-r9IWamBRs",
        "outputId": "f18098fd-f8be-4a50-b667-2a6c93746e3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.724025974025974\n",
            "Confusion Matrix:\n",
            "[[186  20]\n",
            " [ 65  37]]\n",
            "Cost: 345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_mat_tree)\n",
        "\n",
        "# Calculate the cost of the classifier\n",
        "cost = np.sum(confusion_mat_tree * cost_matrix)\n",
        "\n",
        "# Print the cost\n",
        "print(\"Cost:\", cost)"
      ],
      "metadata": {
        "id": "f9Sat5A5miS9",
        "outputId": "6b1d46cb-f7ce-4853-e399-78e521c83ffd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[152  54]\n",
            " [ 29  73]]\n",
            "Cost: 199\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Generar la matriz de confusión para la anterior clasificador, y calcula su costo multiplicando por la matriz de costo\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Generate the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Print the confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Calculate the cost of the classifier\n",
        "cost = np.sum(cm * cost_matrix)\n",
        "\n",
        "# Print the cost\n",
        "print(\"Cost:\", cost)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHeFGjIqYlCW",
        "outputId": "acf5281f-a5cd-4847-9711-6a4ff2e497ba"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[447   4]\n",
            " [241   0]]\n",
            "Cost: 245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "id": "fvZc8Rv0oPBp",
        "outputId": "186c7aa9-24ba-4e32-952b-3843fecbc463",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0         1         2         3         4         5         6  \\\n",
              "0   -1.141852 -0.841722 -3.572597 -1.288212 -0.692891 -4.060474 -0.651972   \n",
              "1    1.233880  0.128489  1.390387 -1.288212 -0.692891 -4.060474 -0.724455   \n",
              "2   -0.844885 -0.309671  0.873409 -0.096379 -0.692891 -0.240205 -0.993245   \n",
              "3    0.936914  2.350587  1.080200 -1.288212 -0.692891  0.990912 -0.063049   \n",
              "4   -0.547919  1.161295  1.080200 -1.288212 -0.692891 -0.049826  1.006073   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "455  0.342981  0.566649 -0.263941  0.907270  0.522715 -0.430583 -0.183854   \n",
              "456 -0.844885 -0.779128  2.734528 -1.288212 -0.692891 -1.217483 -0.799958   \n",
              "457  1.827813 -0.622642  0.873409  1.032726 -0.692891  1.727044  2.005732   \n",
              "458 -1.141852  0.629244 -3.572597 -1.288212 -0.692891  1.320902 -0.805998   \n",
              "459 -1.141852  0.128489  1.390387 -1.288212 -0.692891 -1.204791 -0.633851   \n",
              "\n",
              "            7  Outcome  \n",
              "0   -0.701198        0  \n",
              "1    1.766346        1  \n",
              "2   -0.871374        0  \n",
              "3    0.660206        1  \n",
              "4    2.787399        1  \n",
              "..        ...      ...  \n",
              "455 -0.616111        0  \n",
              "456 -0.531023        0  \n",
              "457  0.404942        1  \n",
              "458 -0.360847        1  \n",
              "459 -1.041549        0  \n",
              "\n",
              "[460 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a626453f-ba7a-4777-a93f-10a47076ef2e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.141852</td>\n",
              "      <td>-0.841722</td>\n",
              "      <td>-3.572597</td>\n",
              "      <td>-1.288212</td>\n",
              "      <td>-0.692891</td>\n",
              "      <td>-4.060474</td>\n",
              "      <td>-0.651972</td>\n",
              "      <td>-0.701198</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.233880</td>\n",
              "      <td>0.128489</td>\n",
              "      <td>1.390387</td>\n",
              "      <td>-1.288212</td>\n",
              "      <td>-0.692891</td>\n",
              "      <td>-4.060474</td>\n",
              "      <td>-0.724455</td>\n",
              "      <td>1.766346</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.844885</td>\n",
              "      <td>-0.309671</td>\n",
              "      <td>0.873409</td>\n",
              "      <td>-0.096379</td>\n",
              "      <td>-0.692891</td>\n",
              "      <td>-0.240205</td>\n",
              "      <td>-0.993245</td>\n",
              "      <td>-0.871374</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.936914</td>\n",
              "      <td>2.350587</td>\n",
              "      <td>1.080200</td>\n",
              "      <td>-1.288212</td>\n",
              "      <td>-0.692891</td>\n",
              "      <td>0.990912</td>\n",
              "      <td>-0.063049</td>\n",
              "      <td>0.660206</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.547919</td>\n",
              "      <td>1.161295</td>\n",
              "      <td>1.080200</td>\n",
              "      <td>-1.288212</td>\n",
              "      <td>-0.692891</td>\n",
              "      <td>-0.049826</td>\n",
              "      <td>1.006073</td>\n",
              "      <td>2.787399</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>455</th>\n",
              "      <td>0.342981</td>\n",
              "      <td>0.566649</td>\n",
              "      <td>-0.263941</td>\n",
              "      <td>0.907270</td>\n",
              "      <td>0.522715</td>\n",
              "      <td>-0.430583</td>\n",
              "      <td>-0.183854</td>\n",
              "      <td>-0.616111</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456</th>\n",
              "      <td>-0.844885</td>\n",
              "      <td>-0.779128</td>\n",
              "      <td>2.734528</td>\n",
              "      <td>-1.288212</td>\n",
              "      <td>-0.692891</td>\n",
              "      <td>-1.217483</td>\n",
              "      <td>-0.799958</td>\n",
              "      <td>-0.531023</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>457</th>\n",
              "      <td>1.827813</td>\n",
              "      <td>-0.622642</td>\n",
              "      <td>0.873409</td>\n",
              "      <td>1.032726</td>\n",
              "      <td>-0.692891</td>\n",
              "      <td>1.727044</td>\n",
              "      <td>2.005732</td>\n",
              "      <td>0.404942</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>458</th>\n",
              "      <td>-1.141852</td>\n",
              "      <td>0.629244</td>\n",
              "      <td>-3.572597</td>\n",
              "      <td>-1.288212</td>\n",
              "      <td>-0.692891</td>\n",
              "      <td>1.320902</td>\n",
              "      <td>-0.805998</td>\n",
              "      <td>-0.360847</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>459</th>\n",
              "      <td>-1.141852</td>\n",
              "      <td>0.128489</td>\n",
              "      <td>1.390387</td>\n",
              "      <td>-1.288212</td>\n",
              "      <td>-0.692891</td>\n",
              "      <td>-1.204791</td>\n",
              "      <td>-0.633851</td>\n",
              "      <td>-1.041549</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>460 rows × 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a626453f-ba7a-4777-a93f-10a47076ef2e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a626453f-ba7a-4777-a93f-10a47076ef2e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a626453f-ba7a-4777-a93f-10a47076ef2e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e286d632-ae9f-457d-ac16-3aa04a86f95e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e286d632-ae9f-457d-ac16-3aa04a86f95e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e286d632-ae9f-457d-ac16-3aa04a86f95e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e2ae627c-60af-4ed5-9631-8c38df785fd3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e2ae627c-60af-4ed5-9631-8c38df785fd3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 460,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9703568378489672,\n        \"min\": -1.1418515161634994,\n        \"max\": 3.906578350084603,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          -1.1418515161634994,\n          1.2338801856003137,\n          -0.2509521280020695\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0026668077752792,\n        \"min\": -3.78365371377963,\n        \"max\": 2.4444782063079162,\n        \"num_unique_values\": 125,\n        \"samples\": [\n          -3.78365371377963,\n          0.034598016123287834,\n          0.09719230677743403\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8893162168083433,\n        \"min\": -3.572597239872642,\n        \"max\": 2.734528247420465,\n        \"num_unique_values\": 41,\n        \"samples\": [\n          -0.8843142452886948,\n          0.6666182515866594,\n          0.046245252836517724\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9699167675703028,\n        \"min\": -1.2882122129452358,\n        \"max\": 2.6636556358464394,\n        \"num_unique_values\": 46,\n        \"samples\": [\n          1.722734719467469,\n          1.2836382918239493,\n          2.6636556358464394\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 4,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0109703353098096,\n        \"min\": -0.6928905722954675,\n        \"max\": 6.65283937836846,\n        \"num_unique_values\": 141,\n        \"samples\": [\n          0.9568596530309466,\n          -0.02430758624213128,\n          -0.5018668619945142\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 5,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9591044228822795,\n        \"min\": -4.060473872668307,\n        \"max\": 3.478529301571733,\n        \"num_unique_values\": 205,\n        \"samples\": [\n          1.4605133003862676,\n          -1.4713212673737484,\n          0.7116897527765668\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 6,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0575209507970265,\n        \"min\": -1.1895531764897842,\n        \"max\": 5.88356476587794,\n        \"num_unique_values\": 363,\n        \"samples\": [\n          0.5288943509257733,\n          1.0845961875592751,\n          -0.8543200033032695\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 7,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9925361067767541,\n        \"min\": -1.0415494364835023,\n        \"max\": 4.063715751598595,\n        \"num_unique_values\": 49,\n        \"samples\": [\n          0.5751178730758285,\n          0.915468885614635,\n          2.1917851826351593\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Outcome\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    }
  ]
}